{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter:\n",
    "    def __init__(self, width, height, depth):\n",
    "        self.weights = np.random.uniform(-1e-4, 1e-4, (depth, height, width))\n",
    "        self.bias = 0\n",
    "        self.weights_grad = np.zeros(self.weights.shape)\n",
    "        self.bias_grad = 0\n",
    "    def __repr__(self):\n",
    "        return \"filter weights=\\n{}\\nbias=\\n{}\".format(repr(self.weights), repr(self.bias))\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    def get_bias(self):\n",
    "        return self.bias\n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.weights_grad\n",
    "        self.bias -= learning_rate * self.bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(input_array, zp):\n",
    "    if zp == 0:\n",
    "        return input_array\n",
    "    else:\n",
    "        if input_array.ndim == 3:\n",
    "            input_width = input_array.shape[2]\n",
    "            input_height = input_array.shape[1]\n",
    "            input_depth = input_array.shape[0]\n",
    "            padded_array = np.zeros((input_depth, input_height+2*zp, input_width+2*zp))\n",
    "            padded_array[:, zp : zp+input_height, zp : zp+input_width] = input_array\n",
    "            return padded_array\n",
    "        elif input_array.ndim == 2:\n",
    "            input_width = input_array.shape[1]\n",
    "            input_height = input_array.shape[0]\n",
    "            padded_array = np.zeros((input_height+2*zp, input_width+2*zp))\n",
    "            padded_array[zp : zp+input_height, zp : zp+input_width] = input_array\n",
    "            return padded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 2)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "np.unravel_index(a.argmax(), a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(input_array, i, j, filter_width, filter_height, stride):\n",
    "    start_i = i * stride\n",
    "    start_j = j * stride\n",
    "    if input_array.ndim == 2:\n",
    "        return input_array[start_i:start_i+filter_height, start_j:start_j+filter_width]\n",
    "    elif input_array.ndim == 3:\n",
    "        return input_array[:, start_i:start_i+filter_height, start_j:start_j+filter_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(array):\n",
    "    return np.unravel_index(array.argmax(), array.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_array, kernel_array, output_array, stride, bias):\n",
    "    channel_number = input_array.ndim\n",
    "    output_width = output_array.shape[1]\n",
    "    output_height = output_array.shape[0]\n",
    "    kernel_width = kernel_array.shape[-1]\n",
    "    kernel_height = kernel_array.shape[-2]\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            output_array[i][j] = (get_patch(input_array, i, j, kernel_width, \\\n",
    "                                  kernel_height, stride) * kernel_array).sum() + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_wise_op(array, op):\n",
    "    for i in np.nditer(array, op_flags=[\"readwrite\"]):\n",
    "        i[...] = op(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, weight_input):\n",
    "        return max(0, weight_input)\n",
    "    def backward(self, ouput):\n",
    "        return 1 if ouput > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1, 0, 1],\n       [1, 1, 0]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "a=np.array([[1,-2,3],[4,6,-1]])\n",
    "ar= Relu()\n",
    "element_wise_op(a,ar.backward)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, input_width, input_height, channel_number, filter_width, \\ \n",
    "                 filter_height, filter_number, zero_padding, stride, activator, learnig_rate):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.filter_number = filter_number\n",
    "        self.zero_padding = zero_padding\n",
    "        self.stride = stride\n",
    "        self.output_width = ConvLayer.calc_output_size(input_width, filter_width)\n",
    "        self.output_height = ConvLayer.calc_output_size(input_height, filter_height)\n",
    "        self.output_array = np.zero((filter_number, self.output_height, self.output_width))\n",
    "        self.filters = []\n",
    "        for _ in range(filter_number):\n",
    "            self.filters.append(Filter(filter_width, filter_height, self.channel_number))\n",
    "        self.activator = activator\n",
    "        self.learnig_rate = learnig_rate\n",
    "        @classmethod\n",
    "        def calc_output_size(cls, input_szie, filter_size):\n",
    "            return (input_szie-filter_size+2*cls.zero_padding) / cls.stride +1\n",
    "        def forward(self, input_array):\n",
    "            self.input_array = input_array\n",
    "            self.padded_input_array = padding(input_array, self.zero_padding)\n",
    "            for i in range(self.filter_number):\n",
    "                filter = self.filters[i]\n",
    "                conv(self.padded_input_array, filter.get_weight(), self.output_array[i], \\\n",
    "                     self.stride, filter.get_bias())\n",
    "                element_wise_op(self.output_array, self.activator.forward)\n",
    "        def expand_sensitivity_map(self, sensitivity_array):\n",
    "            depth = sensitivity_array.shape[0]\n",
    "            expanded_width = (self.input_width-self.filter_width+2*self.zero_padding+1)\n",
    "            expanded_height = (self.input_height-self.filter_height+2*self.zero_padding+1)\n",
    "            expand_array = np.zeros((depth, expanded_height, expanded_width))\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    i_pos = i * self.stride\n",
    "                    j_pos = j * self.stride\n",
    "                    expand_array[:,i_pos,j_pos] = sensitivity_array[:,i,j]\n",
    "            return expand_array\n",
    "        def create_delta_array(self):\n",
    "            return np.zeros((self.channel_number, self.input_height, self.width))\n",
    "        def bp_gradient(self, sensitivity_array):\n",
    "            expanded_array = self.expand_sensitivity_map(sensitivity_array)\n",
    "            for f in range(self.filter_number):\n",
    "                filter = self.filters[f]\n",
    "                for d in range(filter.weight.shape[0]):\n",
    "                    conv(self.padded_input_array[d], expanded_array[f], filter.weights_grad[d], 1, 0)\n",
    "                    filter.bias_grad = expanded_array[f].sum()\n",
    "        def bp_sensitivity_map(self, sensitivity_array, activator):\n",
    "            expand_array = self.expand_sensitivity_map(sensitivity_array)\n",
    "            expanded_width = expand_array.shape[2]\n",
    "            zp = (self.input_width+self.filter_width-1-expanded_width) / 2\n",
    "            padded_array = padding(expand_array, zp)\n",
    "            self.delta_array = self.create_delta_array()\n",
    "            for f in range(self.filter_number):\n",
    "                filter = self.filters[f]\n",
    "                flipped_weights = np.array(map(lambda i:np.rot90(i,2),filter.get_weight()))\n",
    "                delta_array = self.create_delta_array()\n",
    "                for d in range(delta_array.shape[0]):\n",
    "                    conv(padded_array[f],flipped_weights[d],delta_array[d],1,0)\n",
    "                self.delta_array += delta_array\n",
    "            derivative_array = np.array(self.input_array)\n",
    "            element_wise_op(derivative_array, activator.backward)\n",
    "            self.delta_array *= derivative_array\n",
    "        def backward(self, input_array, sensitivity_array, activator):\n",
    "            self.forward(input_array)\n",
    "            self.bp_sensitivity_map(sensitivity_array, activator)\n",
    "            self.bp_gradient(sensitivity_array)\n",
    "        def update(self):\n",
    "            for filter in self.filters:\n",
    "                filter.update(self.learnig_rate)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}